{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c4accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861fc4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 17:04:05.551341: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dropout, Activation, UpSampling2D, GlobalMaxPooling2D, multiply\n",
    "from tensorflow.keras.backend import max\n",
    "from keras_unet_collection import models, base, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9e78ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "sys.path.insert(0,'../..')\n",
    "from gp2 import Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc75325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** GP2 ***\n",
      "Working directory: /tmp/tmpf6gch1s2GP2\n",
      "Verbose mode active!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan.zurrin001/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "2023-04-17 17:04:20.201585: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-04-17 17:04:20.335117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:07:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2023-04-17 17:04:20.335159: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-04-17 17:04:20.339053: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-04-17 17:04:20.339087: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-04-17 17:04:20.340092: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-17 17:04:20.340422: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-17 17:04:20.340998: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-04-17 17:04:20.341863: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-04-17 17:04:20.342109: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-04-17 17:04:20.350725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 8)  80          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 8)  32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512, 512, 8)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 8)  584         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 8)  32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512, 512, 8)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 8)  584         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512, 512, 8)  32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512, 512, 8)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 512, 512, 8)  584         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 512, 512, 8)  32          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512, 512, 8)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 8)  0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 256, 16) 1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256, 256, 16) 64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256, 256, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 16) 2320        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 256, 16) 64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256, 256, 16) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 256, 16) 2320        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256, 256, 16) 64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 256, 256, 16) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 256, 16) 2320        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256, 256, 16) 64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 256, 256, 16) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 16) 0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128, 128, 32) 128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128, 128, 32) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 128, 128, 32) 9248        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128, 128, 32) 128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128, 128, 32) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 128, 32) 9248        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128, 128, 32) 128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 128, 128, 32) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 128, 32) 9248        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128, 128, 32) 128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128, 128, 32) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 32)   0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 64, 64, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 64)   36928       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 64)   36928       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64, 64, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 64)   36928       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 64)   256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 64, 64, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 64)   0           dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 128)  147584      dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 32, 32, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 128)  147584      dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 32, 32, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 128)  147584      dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 32, 32, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 64, 64, 64)   32832       dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 128)  0           conv2d_transpose[0][0]           \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 64)   73792       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 64, 64, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 64)   36928       dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 64, 64, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 64)   36928       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64, 64, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 64, 64, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 64)   36928       dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 64, 64, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 32) 8224        dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 64) 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 128, 128, 32) 128         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 128, 128, 32) 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 128, 128, 32) 9248        dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 128, 128, 32) 128         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 128, 128, 32) 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 128, 128, 32) 9248        dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 128, 128, 32) 128         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 128, 128, 32) 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 128, 128, 32) 9248        dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 128, 128, 32) 128         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 128, 128, 32) 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 16) 2064        dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 32) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 256, 256, 16) 64          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 256, 256, 16) 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 256, 256, 16) 2320        dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 256, 256, 16) 64          conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 256, 256, 16) 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 256, 256, 16) 2320        dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 256, 256, 16) 64          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 256, 256, 16) 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 256, 256, 16) 2320        dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 256, 256, 16) 64          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 256, 256, 16) 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 512, 512, 8)  520         dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 16) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 512, 512, 8)  1160        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 512, 512, 8)  32          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 512, 512, 8)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 512, 512, 8)  584         dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 512, 512, 8)  32          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 512, 512, 8)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 512, 512, 8)  584         dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 512, 512, 8)  32          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 512, 512, 8)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 512, 512, 8)  584         dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 512, 512, 8)  32          conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 512, 512, 8)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 512, 512, 1)  73          dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 512, 512, 1)  2           conv2d_36[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 983,115\n",
      "Trainable params: 980,171\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 17:04:20.351557: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 17:04:20.355775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:07:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2023-04-17 17:04:20.363173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-04-17 17:04:20.363200: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-04-17 17:04:21.061312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-04-17 17:04:21.061363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-04-17 17:04:21.061369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-04-17 17:04:21.069390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38425 MB memory) -> physical GPU (device: 0, name: A100-SXM4-40GB, pci bus id: 0000:07:00.0, compute capability: 8.0)\n"
     ]
    }
   ],
   "source": [
    "R = Runner(verbose=True, classifier='unetplus', base_filters=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b0c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our larger toy dataset (10k images and masks)\n",
    "images = np.load('/hpcstor6/scratch01/r/ryan.zurrin001/GP2TOYEXAMPLE_LARGE/images.npy')\n",
    "masks = np.load('/hpcstor6/scratch01/r/ryan.zurrin001/GP2TOYEXAMPLE_LARGE/masks.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5b4179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 512, 512, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57033c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 512, 512, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "393c7029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "print(images.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97eca1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(images.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2821eb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(masks.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dd71668",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'A': 0.5,\n",
    "    'A_train': 0.1,\n",
    "    'A_val': 0.3,\n",
    "    'A_test': 0.6,\n",
    "    'B': 0.3,\n",
    "    'B_train': 0.7,\n",
    "    'B_val': 0.1,\n",
    "    'B_test': 0.2,\n",
    "    'Z': 0.2\n",
    "}\n",
    "PERCENT_TO_REPLACE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a5d1030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights OK!\n"
     ]
    }
   ],
   "source": [
    "R.setup_data(images, masks, dataset_size=10000, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99127251",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff85c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "RUN: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 17:05:28.359103: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-04-17 17:05:28.379051: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2245755000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 17:05:31.684685: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-04-17 17:05:32.697601: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8201\n",
      "2023-04-17 17:05:33.773301: W tensorflow/stream_executor/gpu/asm_compiler.cc:191] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.0\n",
      "2023-04-17 17:05:33.773324: W tensorflow/stream_executor/gpu/asm_compiler.cc:194] Used ptxas at ptxas\n",
      "2023-04-17 17:05:33.773795: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Unimplemented: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-04-17 17:05:33.852775: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-04-17 17:05:34.948221: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 30s 2s/step - loss: 1.1257 - dice_coef: 0.1643 - val_loss: 1.1060 - val_dice_coef: 0.1703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 17:06:02.602052: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 1.1153 - dice_coef: 0.1682 - val_loss: 1.0772 - val_dice_coef: 0.1702\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 1.0948 - dice_coef: 0.1754 - val_loss: 1.0553 - val_dice_coef: 0.1700\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 1.0712 - dice_coef: 0.1829 - val_loss: 1.0353 - val_dice_coef: 0.1697\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 1.0498 - dice_coef: 0.1889 - val_loss: 1.0159 - val_dice_coef: 0.1695\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 1.0265 - dice_coef: 0.1959 - val_loss: 0.9970 - val_dice_coef: 0.1692\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 1.0056 - dice_coef: 0.2003 - val_loss: 0.9787 - val_dice_coef: 0.1689\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.9873 - dice_coef: 0.2039 - val_loss: 0.9613 - val_dice_coef: 0.1686\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.9706 - dice_coef: 0.2067 - val_loss: 0.9447 - val_dice_coef: 0.1684\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.9551 - dice_coef: 0.2087 - val_loss: 0.9294 - val_dice_coef: 0.1682\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.9410 - dice_coef: 0.2110 - val_loss: 1.0083 - val_dice_coef: 0.1920\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.9281 - dice_coef: 0.2126 - val_loss: 1.2397 - val_dice_coef: 0.1906\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.9161 - dice_coef: 0.2143 - val_loss: 1.2961 - val_dice_coef: 0.1904\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.9050 - dice_coef: 0.2157 - val_loss: 1.3859 - val_dice_coef: 0.1870\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.8947 - dice_coef: 0.2170 - val_loss: 1.4494 - val_dice_coef: 0.1842\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.8851 - dice_coef: 0.2184 - val_loss: 1.5075 - val_dice_coef: 0.1814\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.8762 - dice_coef: 0.2193 - val_loss: 1.5360 - val_dice_coef: 0.1799\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.8677 - dice_coef: 0.2204 - val_loss: 1.5511 - val_dice_coef: 0.1791\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.8594 - dice_coef: 0.2217 - val_loss: 1.6044 - val_dice_coef: 0.1763\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.8516 - dice_coef: 0.2225 - val_loss: 1.6096 - val_dice_coef: 0.1760\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.8451 - dice_coef: 0.2231 - val_loss: 1.6273 - val_dice_coef: 0.1751\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.8372 - dice_coef: 0.2238 - val_loss: 1.5658 - val_dice_coef: 0.1783\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.8299 - dice_coef: 0.2249 - val_loss: 1.5365 - val_dice_coef: 0.1799\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.8230 - dice_coef: 0.2256 - val_loss: 1.5288 - val_dice_coef: 0.1803\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.8163 - dice_coef: 0.2268 - val_loss: 1.5362 - val_dice_coef: 0.1799\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.8100 - dice_coef: 0.2275 - val_loss: 1.5647 - val_dice_coef: 0.1783\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.8042 - dice_coef: 0.2281 - val_loss: 1.6278 - val_dice_coef: 0.1748\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7986 - dice_coef: 0.2291 - val_loss: 1.6267 - val_dice_coef: 0.1748\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7931 - dice_coef: 0.2296 - val_loss: 1.6266 - val_dice_coef: 0.1748\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7882 - dice_coef: 0.2302 - val_loss: 1.6250 - val_dice_coef: 0.1748\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7837 - dice_coef: 0.2310 - val_loss: 1.6231 - val_dice_coef: 0.1749\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7791 - dice_coef: 0.2316 - val_loss: 1.6205 - val_dice_coef: 0.1750\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7749 - dice_coef: 0.2319 - val_loss: 1.6190 - val_dice_coef: 0.1750\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7708 - dice_coef: 0.2329 - val_loss: 1.6132 - val_dice_coef: 0.1753\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7672 - dice_coef: 0.2328 - val_loss: 1.6101 - val_dice_coef: 0.1754\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7634 - dice_coef: 0.2333 - val_loss: 1.6121 - val_dice_coef: 0.1752\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7599 - dice_coef: 0.2340 - val_loss: 1.6038 - val_dice_coef: 0.1756\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7565 - dice_coef: 0.2343 - val_loss: 1.6108 - val_dice_coef: 0.1752\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7533 - dice_coef: 0.2348 - val_loss: 1.6003 - val_dice_coef: 0.1757\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7500 - dice_coef: 0.2354 - val_loss: 1.5976 - val_dice_coef: 0.1758\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7471 - dice_coef: 0.2352 - val_loss: 1.6052 - val_dice_coef: 0.1754\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7444 - dice_coef: 0.2359 - val_loss: 1.5922 - val_dice_coef: 0.1761\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7417 - dice_coef: 0.2365 - val_loss: 1.5934 - val_dice_coef: 0.1759\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7388 - dice_coef: 0.2367 - val_loss: 1.5910 - val_dice_coef: 0.1760\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7364 - dice_coef: 0.2371 - val_loss: 1.5578 - val_dice_coef: 0.1779\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7336 - dice_coef: 0.2373 - val_loss: 1.5687 - val_dice_coef: 0.1772\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7311 - dice_coef: 0.2376 - val_loss: 1.5532 - val_dice_coef: 0.1780\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7286 - dice_coef: 0.2381 - val_loss: 1.5486 - val_dice_coef: 0.1783\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7264 - dice_coef: 0.2383 - val_loss: 1.5431 - val_dice_coef: 0.1785\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7241 - dice_coef: 0.2386 - val_loss: 1.5523 - val_dice_coef: 0.1780\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7220 - dice_coef: 0.2389 - val_loss: 1.5018 - val_dice_coef: 0.1809\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7199 - dice_coef: 0.2392 - val_loss: 1.5354 - val_dice_coef: 0.1788\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7174 - dice_coef: 0.2395 - val_loss: 1.5028 - val_dice_coef: 0.1807\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7156 - dice_coef: 0.2396 - val_loss: 1.5051 - val_dice_coef: 0.1805\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7135 - dice_coef: 0.2396 - val_loss: 1.5018 - val_dice_coef: 0.1807\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7114 - dice_coef: 0.2406 - val_loss: 1.5290 - val_dice_coef: 0.1791\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7095 - dice_coef: 0.2405 - val_loss: 1.5095 - val_dice_coef: 0.1802\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7077 - dice_coef: 0.2406 - val_loss: 1.5098 - val_dice_coef: 0.1801\n",
      "Epoch 59/100\n",
      "1/8 [==>...........................] - ETA: 5s - loss: 0.7055 - dice_coef: 0.2423"
     ]
    }
   ],
   "source": [
    "for run in range(RUNS):\n",
    "    print('***')\n",
    "    print('RUN:', run)\n",
    "    t0 = time.time()\n",
    "    R.run_classifier()\n",
    "    R.run_discriminator()\n",
    "    l = R.find_machine_labels()\n",
    "    if l == 0:\n",
    "        print('No more machine labels.')\n",
    "        print('TOOK', time.time()-t0, 'seconds')\n",
    "        break\n",
    "    R.relabel(percent_to_replace=PERCENT_TO_REPLACE)\n",
    "    print('TOOK', time.time()-t0, 'seconds')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6fd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00075332",
   "metadata": {},
   "outputs": [],
   "source": [
    "R.classifier_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35105656",
   "metadata": {},
   "outputs": [],
   "source": [
    "R.discriminator_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c93cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "R.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8484e3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79b255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009fcc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba9f845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a721a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 240x240 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "R.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551de181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
