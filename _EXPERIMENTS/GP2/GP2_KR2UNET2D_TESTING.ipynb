{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c4accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e78ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 13:21:53.708383: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-04-25 13:21:55.125429: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-04-25 13:21:55.171862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2023-04-25 13:21:55.174419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:47:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2023-04-25 13:21:55.174434: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-04-25 13:21:55.177861: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-04-25 13:21:55.177892: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-04-25 13:21:55.178840: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-25 13:21:55.179187: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-25 13:21:55.179976: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-04-25 13:21:55.180790: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-04-25 13:21:55.181093: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-04-25 13:21:55.191484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "sys.path.insert(0,'../..')\n",
    "from keras import losses, metrics\n",
    "from tensorflow.keras import optimizers\n",
    "import gp2\n",
    "from gp2 import Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06312ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KR2UNet2dD in module gp2.gp2.classifiers.k_r2_unet2d:\n",
      "\n",
      "class KR2UNet2dD(gp2.gp2.classifiers.base_keras_segmentation_classifier.BaseKerasSegmentationClassifier)\n",
      " |  KR2UNet2dD(input_size=(512, 512, 1), filter_num=None, n_labels=1, stack_num_down=2, stack_num_up=2, recur_num=2, activation='PReLU', output_activation='Sigmoid', batch_norm=False, pool=False, unpool=False, name='r2_unet', optimizer=None, loss=None, metric=None, verbose=False, workingdir='/tmp')\n",
      " |  \n",
      " |  Keras UNet2D\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KR2UNet2dD\n",
      " |      gp2.gp2.classifiers.base_keras_segmentation_classifier.BaseKerasSegmentationClassifier\n",
      " |      gp2.gp2.classifiers.classifier.Classifier\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_size=(512, 512, 1), filter_num=None, n_labels=1, stack_num_down=2, stack_num_up=2, recur_num=2, activation='PReLU', output_activation='Sigmoid', batch_norm=False, pool=False, unpool=False, name='r2_unet', optimizer=None, loss=None, metric=None, verbose=False, workingdir='/tmp')\n",
      " |      Recurrent Residual (R2) U-Net\n",
      " |      \n",
      " |      r2_unet_2d(input_size, filter_num, n_labels,\n",
      " |                 stack_num_down=2, stack_num_up=2, recur_num=2,\n",
      " |                 activation='ReLU', output_activation='Softmax',\n",
      " |                 batch_norm=False, pool=True, unpool=True, name='r2_unet')\n",
      " |      \n",
      " |      ----------\n",
      " |      Alom, M.Z., Hasan, M., Yakopcic, C., Taha, T.M. and Asari, V.K., 2018. Recurrent residual convolutional neural network\n",
      " |      based on u-net (r2u-net) for medical image segmentation. arXiv preprint arXiv:1802.06955.\n",
      " |      \n",
      " |      Input\n",
      " |      ----------\n",
      " |          input_size: the size/shape of network input, e.g., `(128, 128, 3)`.\n",
      " |          filter_num: a list that defines the number of filters for each                         down- and upsampling levels. e.g., `[64, 128, 256, 512]`.\n",
      " |                      The depth is expected as `len(filter_num)`.\n",
      " |          n_labels: number of output labels.\n",
      " |          stack_num_down: number of stacked recurrent convolutional layers per downsampling level/block.\n",
      " |          stack_num_down: number of stacked recurrent convolutional layers per upsampling level/block.\n",
      " |          recur_num: number of recurrent iterations.\n",
      " |          activation: one of the `tensorflow.keras.layers` or `keras_unet_collection.activations` interfaces, e.g., 'ReLU'.\n",
      " |          output_activation: one of the `tensorflow.keras.layers` or `keras_unet_collection.activations` interface or 'Sigmoid'.\n",
      " |                             Default option is 'Softmax'.\n",
      " |                             if None is received, then linear activation is applied.\n",
      " |          batch_norm: True for batch normalization.\n",
      " |          pool: True or 'max' for MaxPooling2D.\n",
      " |                'ave' for AveragePooling2D.\n",
      " |                False for strided conv + batch norm + activation.\n",
      " |          unpool: True or 'bilinear' for Upsampling2D with bilinear interpolation.\n",
      " |                  'nearest' for Upsampling2D with nearest interpolation.\n",
      " |                  False for Conv2DTranspose + batch norm + activation.\n",
      " |          name: prefix of the created keras layers.\n",
      " |      \n",
      " |      Output\n",
      " |      ----------\n",
      " |          model: a keras model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gp2.gp2.classifiers.base_keras_segmentation_classifier.BaseKerasSegmentationClassifier:\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  build(self)\n",
      " |  \n",
      " |  predict(self, X_test, y_pred, threshold=0.5)\n",
      " |  \n",
      " |  train(self, X_train, y_train, X_val, y_val, patience_counter=2, batch_size=64, epochs=100, call_backs=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gp2.gp2.classifiers.classifier.Classifier:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gp2.KR2UNet2dD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c14d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc75325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 13:21:55.335036: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-25 13:21:55.592631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2023-04-25 13:21:55.595337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:47:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2023-04-25 13:21:55.604811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2023-04-25 13:21:55.604866: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-04-25 13:21:56.457378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-04-25 13:21:56.457430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 \n",
      "2023-04-25 13:21:56.457436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N Y \n",
      "2023-04-25 13:21:56.457440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   Y N \n",
      "2023-04-25 13:21:56.470012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38425 MB memory) -> physical GPU (device: 0, name: A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0)\n",
      "2023-04-25 13:21:56.472699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 38425 MB memory) -> physical GPU (device: 1, name: A100-SXM4-40GB, pci bus id: 0000:47:00.0, compute capability: 8.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** GP2 R2UNet2dD ***\n",
      "Working directory: /tmp/tmp0z5f50n3GP2\n",
      "Verbose mode active!\n",
      "{'verbose': True, 'workingdir': '/tmp/tmp0z5f50n3GP2', 'input_size': (512, 512, 1), 'filter_num': [16, 32, 64, 128], 'stack_num_down': 2, 'stack_num_up': 2, 'recur_num': 1, 'n_labels': 1, 'activation': 'ReLU', 'output_activation': 'Sigmoid', 'batch_norm': False, 'pool': True, 'unpool': True, 'name': 'r2_unet', 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7ff1a01379a0>, 'loss': <function binary_crossentropy at 0x7ff1a8195b80>, 'metric': [<function binary_accuracy at 0x7ff1a803faf0>], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7ff18c9c1250>}\n",
      "Model summary:\n",
      "Model: \"r2_unet_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "r2_unet_input (InputLayer)      [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down0_conv (Conv2D)     (None, 512, 512, 16) 32          r2_unet_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down0_conv0 (Conv2D)    (None, 512, 512, 16) 2320        r2_unet_down0_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down0_activation0 (ReLU (None, 512, 512, 16) 0           r2_unet_down0_conv0[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down0_add0_0 (Add)      (None, 512, 512, 16) 0           r2_unet_down0_activation0[0][0]  \n",
      "                                                                 r2_unet_down0_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down0_conv0_0 (Conv2D)  (None, 512, 512, 16) 2320        r2_unet_down0_add0_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down0_activation0_0 (Re (None, 512, 512, 16) 0           r2_unet_down0_conv0_0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down0_conv1 (Conv2D)    (None, 512, 512, 16) 2320        r2_unet_down0_activation0_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down0_activation1 (ReLU (None, 512, 512, 16) 0           r2_unet_down0_conv1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down0_add1_0 (Add)      (None, 512, 512, 16) 0           r2_unet_down0_activation1[0][0]  \n",
      "                                                                 r2_unet_down0_activation0_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down0_conv1_0 (Conv2D)  (None, 512, 512, 16) 2320        r2_unet_down0_add1_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down0_activation1_0 (Re (None, 512, 512, 16) 0           r2_unet_down0_conv1_0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down0_add1 (Add)        (None, 512, 512, 16) 0           r2_unet_down0_activation1_0[0][0]\n",
      "                                                                 r2_unet_down0_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down1_encode_maxpool (M (None, 256, 256, 16) 0           r2_unet_down0_add1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down1_conv (Conv2D)     (None, 256, 256, 32) 544         r2_unet_down1_encode_maxpool[0][0\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down1_conv0 (Conv2D)    (None, 256, 256, 32) 9248        r2_unet_down1_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down1_activation0 (ReLU (None, 256, 256, 32) 0           r2_unet_down1_conv0[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down1_add0_0 (Add)      (None, 256, 256, 32) 0           r2_unet_down1_activation0[0][0]  \n",
      "                                                                 r2_unet_down1_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down1_conv0_0 (Conv2D)  (None, 256, 256, 32) 9248        r2_unet_down1_add0_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down1_activation0_0 (Re (None, 256, 256, 32) 0           r2_unet_down1_conv0_0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down1_conv1 (Conv2D)    (None, 256, 256, 32) 9248        r2_unet_down1_activation0_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down1_activation1 (ReLU (None, 256, 256, 32) 0           r2_unet_down1_conv1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down1_add1_0 (Add)      (None, 256, 256, 32) 0           r2_unet_down1_activation1[0][0]  \n",
      "                                                                 r2_unet_down1_activation0_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down1_conv1_0 (Conv2D)  (None, 256, 256, 32) 9248        r2_unet_down1_add1_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down1_activation1_0 (Re (None, 256, 256, 32) 0           r2_unet_down1_conv1_0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down1_add1 (Add)        (None, 256, 256, 32) 0           r2_unet_down1_activation1_0[0][0]\n",
      "                                                                 r2_unet_down1_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down2_encode_maxpool (M (None, 128, 128, 32) 0           r2_unet_down1_add1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down2_conv (Conv2D)     (None, 128, 128, 64) 2112        r2_unet_down2_encode_maxpool[0][0\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down2_conv0 (Conv2D)    (None, 128, 128, 64) 36928       r2_unet_down2_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down2_activation0 (ReLU (None, 128, 128, 64) 0           r2_unet_down2_conv0[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down2_add0_0 (Add)      (None, 128, 128, 64) 0           r2_unet_down2_activation0[0][0]  \n",
      "                                                                 r2_unet_down2_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down2_conv0_0 (Conv2D)  (None, 128, 128, 64) 36928       r2_unet_down2_add0_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down2_activation0_0 (Re (None, 128, 128, 64) 0           r2_unet_down2_conv0_0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down2_conv1 (Conv2D)    (None, 128, 128, 64) 36928       r2_unet_down2_activation0_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down2_activation1 (ReLU (None, 128, 128, 64) 0           r2_unet_down2_conv1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down2_add1_0 (Add)      (None, 128, 128, 64) 0           r2_unet_down2_activation1[0][0]  \n",
      "                                                                 r2_unet_down2_activation0_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down2_conv1_0 (Conv2D)  (None, 128, 128, 64) 36928       r2_unet_down2_add1_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down2_activation1_0 (Re (None, 128, 128, 64) 0           r2_unet_down2_conv1_0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down2_add1 (Add)        (None, 128, 128, 64) 0           r2_unet_down2_activation1_0[0][0]\n",
      "                                                                 r2_unet_down2_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down3_encode_maxpool (M (None, 64, 64, 64)   0           r2_unet_down2_add1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down3_conv (Conv2D)     (None, 64, 64, 128)  8320        r2_unet_down3_encode_maxpool[0][0\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down3_conv0 (Conv2D)    (None, 64, 64, 128)  147584      r2_unet_down3_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down3_activation0 (ReLU (None, 64, 64, 128)  0           r2_unet_down3_conv0[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down3_add0_0 (Add)      (None, 64, 64, 128)  0           r2_unet_down3_activation0[0][0]  \n",
      "                                                                 r2_unet_down3_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down3_conv0_0 (Conv2D)  (None, 64, 64, 128)  147584      r2_unet_down3_add0_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down3_activation0_0 (Re (None, 64, 64, 128)  0           r2_unet_down3_conv0_0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down3_conv1 (Conv2D)    (None, 64, 64, 128)  147584      r2_unet_down3_activation0_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down3_activation1 (ReLU (None, 64, 64, 128)  0           r2_unet_down3_conv1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down3_add1_0 (Add)      (None, 64, 64, 128)  0           r2_unet_down3_activation1[0][0]  \n",
      "                                                                 r2_unet_down3_activation0_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down3_conv1_0 (Conv2D)  (None, 64, 64, 128)  147584      r2_unet_down3_add1_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down3_activation1_0 (Re (None, 64, 64, 128)  0           r2_unet_down3_conv1_0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_down3_add1 (Add)        (None, 64, 64, 128)  0           r2_unet_down3_activation1_0[0][0]\n",
      "                                                                 r2_unet_down3_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_decode_unpool (UpSa (None, 128, 128, 128 0           r2_unet_down3_add1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_conv_before_concat_ (None, 128, 128, 64) 73792       r2_unet_up1_decode_unpool[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_conv_before_concat_ (None, 128, 128, 64) 0           r2_unet_up1_conv_before_concat_0[\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_concat (Concatenate (None, 128, 128, 128 0           r2_unet_up1_conv_before_concat_0_\n",
      "                                                                 r2_unet_down2_add1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_conv (Conv2D)       (None, 128, 128, 64) 8256        r2_unet_up1_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_conv0 (Conv2D)      (None, 128, 128, 64) 36928       r2_unet_up1_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_activation0 (ReLU)  (None, 128, 128, 64) 0           r2_unet_up1_conv0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_add0_0 (Add)        (None, 128, 128, 64) 0           r2_unet_up1_activation0[0][0]    \n",
      "                                                                 r2_unet_up1_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_conv0_0 (Conv2D)    (None, 128, 128, 64) 36928       r2_unet_up1_add0_0[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_activation0_0 (ReLU (None, 128, 128, 64) 0           r2_unet_up1_conv0_0[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_conv1 (Conv2D)      (None, 128, 128, 64) 36928       r2_unet_up1_activation0_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_activation1 (ReLU)  (None, 128, 128, 64) 0           r2_unet_up1_conv1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_add1_0 (Add)        (None, 128, 128, 64) 0           r2_unet_up1_activation1[0][0]    \n",
      "                                                                 r2_unet_up1_activation0_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_conv1_0 (Conv2D)    (None, 128, 128, 64) 36928       r2_unet_up1_add1_0[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_activation1_0 (ReLU (None, 128, 128, 64) 0           r2_unet_up1_conv1_0[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up1_add1 (Add)          (None, 128, 128, 64) 0           r2_unet_up1_activation1_0[0][0]  \n",
      "                                                                 r2_unet_up1_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_decode_unpool (UpSa (None, 256, 256, 64) 0           r2_unet_up1_add1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_conv_before_concat_ (None, 256, 256, 32) 18464       r2_unet_up2_decode_unpool[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_conv_before_concat_ (None, 256, 256, 32) 0           r2_unet_up2_conv_before_concat_0[\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_concat (Concatenate (None, 256, 256, 64) 0           r2_unet_up2_conv_before_concat_0_\n",
      "                                                                 r2_unet_down1_add1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_conv (Conv2D)       (None, 256, 256, 32) 2080        r2_unet_up2_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_conv0 (Conv2D)      (None, 256, 256, 32) 9248        r2_unet_up2_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_activation0 (ReLU)  (None, 256, 256, 32) 0           r2_unet_up2_conv0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_add0_0 (Add)        (None, 256, 256, 32) 0           r2_unet_up2_activation0[0][0]    \n",
      "                                                                 r2_unet_up2_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_conv0_0 (Conv2D)    (None, 256, 256, 32) 9248        r2_unet_up2_add0_0[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_activation0_0 (ReLU (None, 256, 256, 32) 0           r2_unet_up2_conv0_0[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_conv1 (Conv2D)      (None, 256, 256, 32) 9248        r2_unet_up2_activation0_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_activation1 (ReLU)  (None, 256, 256, 32) 0           r2_unet_up2_conv1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_add1_0 (Add)        (None, 256, 256, 32) 0           r2_unet_up2_activation1[0][0]    \n",
      "                                                                 r2_unet_up2_activation0_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_conv1_0 (Conv2D)    (None, 256, 256, 32) 9248        r2_unet_up2_add1_0[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_activation1_0 (ReLU (None, 256, 256, 32) 0           r2_unet_up2_conv1_0[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up2_add1 (Add)          (None, 256, 256, 32) 0           r2_unet_up2_activation1_0[0][0]  \n",
      "                                                                 r2_unet_up2_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_decode_unpool (UpSa (None, 512, 512, 32) 0           r2_unet_up2_add1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_conv_before_concat_ (None, 512, 512, 16) 4624        r2_unet_up3_decode_unpool[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_conv_before_concat_ (None, 512, 512, 16) 0           r2_unet_up3_conv_before_concat_0[\n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_concat (Concatenate (None, 512, 512, 32) 0           r2_unet_up3_conv_before_concat_0_\n",
      "                                                                 r2_unet_down0_add1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_conv (Conv2D)       (None, 512, 512, 16) 528         r2_unet_up3_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_conv0 (Conv2D)      (None, 512, 512, 16) 2320        r2_unet_up3_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_activation0 (ReLU)  (None, 512, 512, 16) 0           r2_unet_up3_conv0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_add0_0 (Add)        (None, 512, 512, 16) 0           r2_unet_up3_activation0[0][0]    \n",
      "                                                                 r2_unet_up3_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_conv0_0 (Conv2D)    (None, 512, 512, 16) 2320        r2_unet_up3_add0_0[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_activation0_0 (ReLU (None, 512, 512, 16) 0           r2_unet_up3_conv0_0[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_conv1 (Conv2D)      (None, 512, 512, 16) 2320        r2_unet_up3_activation0_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_activation1 (ReLU)  (None, 512, 512, 16) 0           r2_unet_up3_conv1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_add1_0 (Add)        (None, 512, 512, 16) 0           r2_unet_up3_activation1[0][0]    \n",
      "                                                                 r2_unet_up3_activation0_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_conv1_0 (Conv2D)    (None, 512, 512, 16) 2320        r2_unet_up3_add1_0[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_activation1_0 (ReLU (None, 512, 512, 16) 0           r2_unet_up3_conv1_0[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_up3_add1 (Add)          (None, 512, 512, 16) 0           r2_unet_up3_activation1_0[0][0]  \n",
      "                                                                 r2_unet_up3_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_output (Conv2D)         (None, 512, 512, 1)  17          r2_unet_up3_add1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "r2_unet_output_activation (Acti (None, 512, 512, 1)  0           r2_unet_output[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,097,073\n",
      "Trainable params: 1,097,073\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Using default discriminator (CNN)\n"
     ]
    }
   ],
   "source": [
    "R = Runner(verbose=True, \n",
    "           classifier='kr2unet2d' , \n",
    "           discriminator='cnn', #cnnplus\n",
    "           filter_num=[16, 32, 64, 128],\n",
    "           stack_num_down=2, \n",
    "           stack_num_up=2, \n",
    "           recur_num=1, \n",
    "           activation='ReLU', \n",
    "           output_activation='Sigmoid', \n",
    "           batch_norm=False, \n",
    "           pool=True, \n",
    "           unpool=True, \n",
    "           optimizer=None, \n",
    "           loss=None, \n",
    "           metric=None,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b0c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our larger toy dataset (10k images and masks)\n",
    "images = np.load('/hpcstor6/scratch01/r/ryan.zurrin001/GP2TOYEXAMPLE_LARGE/images.npy')\n",
    "masks = np.load('/hpcstor6/scratch01/r/ryan.zurrin001/GP2TOYEXAMPLE_LARGE/masks.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7330ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[:5000]\n",
    "masks = masks[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5b4179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 512, 512, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57033c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 512, 512, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd71668",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'A': 0.5,\n",
    "    'A_train': 0.1,\n",
    "    'A_val': 0.3,\n",
    "    'A_test': 0.6,\n",
    "    'B': 0.3,\n",
    "    'B_train': 0.7,\n",
    "    'B_val': 0.1,\n",
    "    'B_test': 0.2,\n",
    "    'Z': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6fd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights OK!\n",
      "******\n",
      "Loop 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 13:22:03.273972: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-04-25 13:22:03.294994: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2245755000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 13:22:05.896884: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-04-25 13:22:06.688230: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-04-25 13:22:06.689520: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-04-25 13:22:07.343819: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8201\n",
      "2023-04-25 13:22:08.000100: W tensorflow/stream_executor/gpu/asm_compiler.cc:191] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.0\n",
      "2023-04-25 13:22:08.000124: W tensorflow/stream_executor/gpu/asm_compiler.cc:194] Used ptxas at ptxas\n",
      "2023-04-25 13:22:08.000179: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Unimplemented: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 20s 3s/step - loss: 9.8222 - binary_accuracy: 0.2515 - val_loss: 9.6194 - val_binary_accuracy: 0.2494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 13:22:25.443064: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "/home/ryan.zurrin001/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 9.8191 - binary_accuracy: 0.2515 - val_loss: 9.6194 - val_binary_accuracy: 0.2494\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 9.8182 - binary_accuracy: 0.2515 - val_loss: 9.6194 - val_binary_accuracy: 0.2494\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 9.8209 - binary_accuracy: 0.2515 - val_loss: 9.6194 - val_binary_accuracy: 0.2494\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 9.8194 - binary_accuracy: 0.2515 - val_loss: 9.6194 - val_binary_accuracy: 0.2494\n",
      "Model saved to: /tmp/tmp0z5f50n3GP2/r2_unet_0r2_unet_model\n",
      "History saved to: /tmp/tmp0z5f50n3GP2/r2_unet_history_0.pkl\n",
      "Testing the classifier...\n"
     ]
    }
   ],
   "source": [
    "R.run(images=images, masks=masks, weights=weights, runs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00075332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11.24902057647705, 0.14587022364139557],\n",
       " [11.22181224822998, 0.1459418386220932]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.classifier_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35105656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 1.0], [0.0, 1.0]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.discriminator_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba17012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a90a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 240x240 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "R.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c8529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1ec788d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 240x240 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "R.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551de181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
